## Paper collection for LLM code generation

## Introduction

## Papers

1. **On-the-Fly Adaptation of Source Code Models using Meta-Learning.** NeurIPS 2020 CAP Workshop

    *Disha Shrivastava, Hugo Larochelle, Daniel Tarlow*  [[pdf](https://arxiv.org/abs/2003.11768v1)], 2020.5.26

1. **Competition-Level Code Generation with AlphaCode.** Science 2022
   
    *Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, Thomas Hubert, Peter Choy, Cyprien de Masson d'Autume, Igor Babuschkin, Xinyun Chen, Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey Cherepanov, James Molloy, Daniel J. Mankowitz, Esme Sutherland Robson, Pushmeet Kohli, Nando de Freitas, Koray Kavukcuoglu, Oriol Vinyals*  [[pdf](https://arxiv.org/abs/2203.07814)], 2022.2.8

1. **Repository-Level Prompt Generation for Large Language Models of Code.** ICML 2023

    *Disha Shrivastava, Hugo Larochelle, Daniel Tarlow*  [[pdf](https://arxiv.org/abs/2206.12839)], 2022.6.26

1. **Language Models Can Teach Themselves to Program Better.** ICLR 2023
   
    *Patrick Haluptzok, Matthew Bowers, Adam Tauman Kalai*  [[pdf](https://arxiv.org/abs/2207.14502)], 2022.7.29

1. **DocPrompting: Generating Code by Retrieving the Docs.** ICLR 2023

    *Shuyan Zhou, Uri Alon, Frank F. Xu, Zhiruo Wang, Zhengbao Jiang, Graham Neubig*  [[pdf](https://arxiv.org/abs/2207.05987)], 2022.7.13

1. **CodeT: Code Generation with Generated Tests.** ICLR 2023

    *Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, Weizhu Chen*  [[pdf](https://arxiv.org/abs/2207.10397)], 2022.7.21

1. **Language Models Can Teach Themselves to Program Better.** ICLR 2023

    *Patrick Haluptzok, Matthew Bowers, Adam Tauman Kalai*  [[pdf](https://arxiv.org/abs/2207.14502)], 2022.7.29

1. **Incorporating Domain Knowledge through Task Augmentation for Front-End JavaScript Code Generation.** ESEC/FSE 2022

    *Sijie Shen, Xiang Zhu, Yihong Dong, Qizhi Guo, Yankun Zhen, Ge Li*  [[pdf](https://arxiv.org/abs/2208.10091)], 2022.8.22

1. **Code4Struct: Code Generation for Few-Shot Event Structure Prediction.** ACL 2023

    *Xingyao Wang, Sha Li, Heng Ji*  [[pdf](https://arxiv.org/abs/2210.12810)], 2022.10.23

1. **DS-1000: A Natural and Reliable Benchmark for Data Science Code Generation.** ICML 2023

    *Yuhang Lai, Chengxi Li, Yiming Wang, Tianyi Zhang, Ruiqi Zhong, Luke Zettlemoyer, Scott Wen-tau Yih, Daniel Fried, Sida Wang, Tao Yu*  [[pdf](https://arxiv.org/abs/2211.11501)], 2022.11.18

1. **Coder Reviewer Reranking for Code Generation.** ICML 2023

    *Tianyi Zhang, Tao Yu, Tatsunori B. Hashimoto, Mike Lewis, Wen-tau Yih, Daniel Fried, Sida I. Wang*  [[pdf](https://arxiv.org/abs/2211.16490)], 2022.11.29

1. **Python Code Generation by Asking Clarification Questions.** ACL 2023

    *Haau-Sing Li, Mohsen Mesgar, André F. T. Martins, Iryna Gurevych*  [[pdf](https://arxiv.org/abs/2212.09885)], 2022.12.19

1. **LEVER: Learning to Verify Language-to-Code Generation with Execution.** ICML 2023

    *Ansong Ni, Srini Iyer, Dragomir Radev, Ves Stoyanov, Wen-tau Yih, Sida I. Wang, Xi Victoria Lin*  [[pdf](https://arxiv.org/abs/2302.08468)], 2023.2.16
   
1. **EvoPrompting: Language Models for Code-Level Neural Architecture Search.** Arxiv

    *Angelica Chen, David M. Dohan, David R. So*  [[pdf](https://arxiv.org/abs/2302.14838)], 2023.2.28
   
1. **Planning with Large Language Models for Code Generation.** ICLR 2023

    *Shun Zhang, Zhenfang Chen, Yikang Shen, Mingyu Ding, Joshua B. Tenenbaum, Chuang Gan.*  [[pdf](https://arxiv.org/abs/2303.05510)], 2023.3.9
   
1. **Self-planning Code Generation with Large Language Model.** Arxiv

    *Xue Jiang, Yihong Dong, Lecheng Wang, Qiwei Shang, Ge Li*  [[pdf](https://arxiv.org/abs/2303.06689)], 2023.3.12
   
1. **Reflexion: Language Agents with Verbal Reinforcement Learning.** Arxiv

    *Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik Narasimhan, Shunyu Yao*  [[pdf](https://arxiv.org/abs/2303.11366)], 2023.3.20

1. **Teaching Large Language Models to Self-Debug.** Arxiv

    *Xinyun Chen, Maxwell Lin, Nathanael Schärli, Denny Zhou*  [[pdf](https://arxiv.org/abs/2304.05128)], 2023.4.11

1. **WizardLM: Empowering Large Language Models to Follow Complex Instructions.** Arxiv

    *Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, Daxin Jiang*  [[pdf](https://arxiv.org/abs/2304.12244)], 2023.4.24

1. **From Words to Code: Harnessing Data for Program Synthesis from Natural Language.** Arxiv

    *Anirudh Khatry, Joyce Cahoon, Jordan Henkel, Shaleen Deep, Venkatesh Emani, Avrilia Floratou, Sumit Gulwani, Vu Le, Mohammad Raza, Sherry Shi, Mukul Singh, Ashish Tiwari*  [[pdf](Anirudh Khatry, Joyce Cahoon, Jordan Henkel, Shaleen Deep, Venkatesh Emani, Avrilia Floratou, Sumit Gulwani, Vu Le, Mohammad Raza, Sherry Shi, Mukul Singh, Ashish Tiwari)], 2023.5.2

1. **Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation.** Arxiv

    *Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, Lingming Zhang*  [[pdf](https://arxiv.org/abs/2305.01210)], 2023.5.2

1. **Text-to-SQL Error Correction with Language Models of Code.** ACL 2023

    *Ziru Chen, Shijie Chen, Michael White, Raymond Mooney, Ali Payani, Jayanth Srinivasa, Yu Su, Huan Sun*  [[pdf](https://arxiv.org/abs/2305.13073)], 2023.5.22

1. **ALGO: Synthesizing Algorithmic Programs with Generated Oracle Verifiers.** Arxiv

    *Kexun Zhang, Danqing Wang, Jingtao Xia, William Yang Wang, Lei Li*  [[pdf](https://arxiv.org/abs/2305.14591)], 2023.5.24

1. **Tuning Models of Code with Compiler-Generated Reinforcement Learning Feedback.** Arxiv
   
    *Abhinav Jain, Chima Adiole, Swarat Chaudhuri, Thomas Reps, Chris Jermaine*  [[pdf](https://arxiv.org/abs/2305.18341)], 2023.5.25

1. **Grammar Prompting for Domain-Specific Language Generation with Large Language Models.** Arxiv

    *Bailin Wang, Zi Wang, Xuezhi Wang, Yuan Cao, Rif A. Saurous, Yoon Kim*  [[pdf](https://arxiv.org/abs/2305.19234)], 2023.5.30
   
1. **WizardCoder: Empowering Code Large Language Models with Evol-Instruct.** Arxiv

    *Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, Daxin Jiang*  [[pdf](https://arxiv.org/abs/2306.08568)], 2023.6.14

1. **Demystifying GPT Self-Repair for Code Generation.** Arxiv

    *Theo X. Olausson, Jeevana Priya Inala, Chenglong Wang, Jianfeng Gao, Armando Solar-Lezama*  [[pdf](https://arxiv.org/abs/2306.09896)], 2023.6.16

1. **RepoFusion: Training Code Models to Understand Your Repository.** Arxiv

    *Disha Shrivastava, Denis Kocetkov, Harm de Vries, Dzmitry Bahdanau, Torsten Scholak*  [[pdf](https://arxiv.org/abs/2306.10998)], 2023.6.19

1. **Guiding Language Models of Code with Global Context using Monitors.** Arxiv

    *Lakshya A Agrawal, Aditya Kanade, Navin Goyal, Shuvendu K. Lahiri, Sriram K. Rajamani*  [[pdf](https://arxiv.org/abs//2306.10763)], 2023.6.19

1. **Textbooks Are All You Need.** Arxiv

    *Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio César Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi, Adil Salim, Shital Shah, Harkirat Singh Behl, Xin Wang, Sébastien Bubeck, Ronen Eldan, Adam Tauman Kalai, Yin Tat Lee, Yuanzhi Li*  [[pdf](https://arxiv.org/abs/2306.11644)], 2023.6.20

1. **Language models are weak learners.** Arxiv

    *Hariharan Manikandan, Yiding Jiang, J Zico Kolter*  [[pdf](https://arxiv.org/abs/2306.14101)], 2023.6.25

1. **LongCoder: A Long-Range Pre-trained Language Model for Code Completion.** Arxiv

    *Daya Guo, Canwen Xu, Nan Duan, Jian Yin, Julian McAuley*  [[pdf](https://arxiv.org/abs/2306.14893)], 2023.6.26

1. **InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback.** Arxiv

    *John Yang, Akshara Prabhakar, Karthik Narasimhan, Shunyu Yao*  [[pdf](https://arxiv.org/abs/2306.14898)], 2023.6.26

